250620
어제 Summary
inertia-elbow(in graph)-군집의 수
인공지능 시스템설계
5p 분석기획 단계/빅데이터 분석 방법론

1) 비즈니스 이해 및 범위 설정
- 비즈니스에 대한 충분한 이해와 도메인에 대한 문제점을 파악
- 향후 프로젝트 진행을 위한 방향을 설정하고, 프로젝트 목적에 부합한 범위 설정
2) 프로젝트 정의 및 계획수립
- 모델의 운영 이미지를 설계하고 모델 평가 기준을 설정
- 프로젝트의 목표 설정, KPI, 목표 수준 구체화하고 상세 프로젝트를 정의, 수행계획
- WBS(Work Breakdown Structure) : 프로젝트나 업무를 세분화하여 계층적으로 분석하고 관리하는 기법(
ㄴ 업무 세분화 : 사람별 업무 분담, 시간계획 > 보고 가능 > 시간에 따른 진행도 확인 > 간트차트
3) 프로젝트 위험계획 수립
- 발생 가능한 위험에 대한 리스트, 영향도, 빈도, 발생가능성 등에 대해 우선순위 설정
- 위험에 대한 대응(회피,전이,완화,수용), 대안등을 구분하여 위험 관리 계획서 작성

4) 타이타닉 데이터셋
- 망원경도 못 썼다는 썰
- AIHub에서 만든 데이터셋 사용해도 됨
- kaggle에서 데이터셋 제공됨 > https://www.kaggle.com/competitions/titanic
- DACON/타이타닉 생존 예측 프로젝트 
ㄴ Target : Survival
ㄴ test set 에는 Survival 값이 없음
ㄴ train set을 realtrain set과 validationset으로 나눠서 결과 예측 및 개선
ㄴ 문제에 따라 코드공유탭에 base line이 포함되어 있기도 함

8p 데이터 준비 단계/ 빅데이터 분석 방법론
1) 필요 데이터 정의
- 비정형 데이터 : 포맷에 맞지 않는 데이터 > 모든 과정은 document로 남길 것
- 데이터 유출 시 발생할 수 있는 문제 파악 > 개인정보유출, 협업(개인간, 기관간 데이터 공유)
2) 데이터 스토어 설계
- 데이터 저장 위치, 저장 형식 등에 대한 고려 > 시스템의 정도에 따라 설계가 필요할 수도
3) 데이터 수집 및 정합성 점검
ex) 넘치는 가짜 정보, 어그로성 기사 제목을 판별해내고 싶다면 > 크롤링을 통한 데이터 수집
- 실 강의 에서는 크롤러에 대한 내용 많음
- 불필요한 데이터 삭제

> 해당 프로젝트 에서는 필요한 data가 주어진 것으로 가정
- 결측치도 있네
- 이름과 성별이 잘 일치하는지
ex) master 2살? : master는 어린 남자아이에게 예이 있게 부르는 전통적인 존칭/현대 영어에서는 거의 사라지긴 했음

-정규화
의사결정트리에서는 정규화 할 필요가 없다.
뉴럴렛 계열을 쓰려면 정규화를 꼭(!) 해야한다.
ㄴ 정규화가 학습에 미치는 영향이 크다.
정규화는 크게 2가지가 있다
1. min-max scaler :순서대로 줄세워서 매핑/대부분 얘로 해결됨
2. Standard scaler : 정규분포에서 표준편차값을 가지고 매핑
3. 정규화 하지 않으면 Fare 값이 Age 값에 비해 크기 때문에 학습속도가 낮아진다.
ㄴ 반대로 정규화를 하면 뉴럴렛에서 학습속도가 비교적 빨라집니다.

-인코딩
String 형태의 명목형 변수(범주형 변수)는 많은 ML 알고리즘에서 적절하게 계산되지 않는다. One-Hot 인코딩을하여
딕셔너리 만들어서 숫자로 0,1,2... 만들면 계산상의 문제로 data가 손상될 수 있다.
예제와 같이 속성 갯수 만큼으로 칼럼을 늘려주고 boolean값을 가지도록 한다.
cardinality가 높다 : 특정 데이터 집합에서 중복되는 값이 적고, 고유한 값의 수가 많다.
카디널리티가 높은 속성의 독립변수의 경우 제외도 고려
	Ticket 데이터는 제외
	Name 데이터도 제외를 고려할 수 있으나 데이터를 최대한 활용하는 차원에서 호칭 부분을 추출해서 활용도를 확인해보자
- 탐색적 분석
상관관계 분석 corr() : 


-전처리 함수 리팩토링
스캐일러 잘 보존해서 같은 입력에 같은 출력이 나오도록 해야함 > 리팩토링함수의 출력으로 저장

-훈련/평가용 데이터 분할
train_X 에서 Label drop 하고 validate set 만들기

-모델별 트레이닝
	SVM : 준지도 학습의 데이터를 가지고 논문?쓴거
	XG부스트 추가하기
- 결과 평가
	XG부스트 평가 결과 추가하기
-제출
	1) submission 양식에 맞춰 제출

pred_y = xgmodel.predict(test_X)
df_submission=pd.DataFrame(pred_y, columns=['Suvived])
df_submission['PassengerId'] = df_test['PassengerId']
df_submission = df_submission.set_index('PassengerId')
df_submission.to_csv(colab_path + 'path')

	2) test_X가 공개되어 있지 않은 경우 : 모델을 제출해야함
	3) 제출 전에 양식에 맞는지 실제로 확인하기	  


colab 주석 설정/해제 단축키 : Ctrl + /
# df_train.describe() # Survived.mean : 0.38 # Age.count를 보면 결측치가 있음을 확인할 수 있음 # ? 왜 8개 data 밖에 안나오나?